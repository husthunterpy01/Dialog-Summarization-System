{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6004344,"sourceType":"datasetVersion","datasetId":3438844},{"sourceId":10000750,"sourceType":"datasetVersion","datasetId":6155682},{"sourceId":10021056,"sourceType":"datasetVersion","datasetId":6170631}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\n\nsamsum_train_dataset = load_dataset(\"csv\", data_files={\"train\": \"/kaggle/input/samsum-dataset-text-summarization/samsum-train.csv\"})\nsamsum_test_dataset = load_dataset(\"csv\", data_files={\"test\": \"/kaggle/input/samsum-dataset-text-summarization/samsum-test.csv\"})\nsamsum_validate_dataset = load_dataset(\"csv\", data_files={\"validation\": \"/kaggle/input/samsum-dataset-text-summarization/samsum-validation.csv\"})\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-30T15:05:22.675948Z","iopub.execute_input":"2024-11-30T15:05:22.676302Z","iopub.status.idle":"2024-11-30T15:05:23.049191Z","shell.execute_reply.started":"2024-11-30T15:05:22.676270Z","shell.execute_reply":"2024-11-30T15:05:23.048539Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# Check the number of rows in each split of the dataset\nprint(f\"Training dataset size: {samsum_train_dataset['train'].num_rows}\")\nprint(f\"Test dataset size: {samsum_test_dataset['test'].num_rows}\")\nprint(f\"Validation dataset size: {samsum_validate_dataset['validation'].num_rows}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T15:05:36.617855Z","iopub.execute_input":"2024-11-30T15:05:36.618793Z","iopub.status.idle":"2024-11-30T15:05:36.625604Z","shell.execute_reply.started":"2024-11-30T15:05:36.618742Z","shell.execute_reply":"2024-11-30T15:05:36.624689Z"}},"outputs":[{"name":"stdout","text":"Training dataset size: 14732\nTest dataset size: 819\nValidation dataset size: 818\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"samsum_train_dataset[\"train\"][25]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T15:05:38.392581Z","iopub.execute_input":"2024-11-30T15:05:38.392934Z","iopub.status.idle":"2024-11-30T15:05:38.399675Z","shell.execute_reply.started":"2024-11-30T15:05:38.392903Z","shell.execute_reply":"2024-11-30T15:05:38.398930Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"{'id': '13810064',\n 'dialogue': 'Julius: dude, your assessment of manutd\\r\\nLawrence: i have nothing to say, im so offended and hopeless of them this season\\r\\nJulius: me too\\r\\nLawrence: i dont even know whats wrong with the team\\r\\nJulius: the quality is there but nothing is happening\\r\\nLawrence: the players look tired of something\\r\\nJulius:  with mourinhos conservative football!!\\r\\nLawrence: its so boring\\r\\nJulius: so lifeless\\r\\nLawrence: man!!\\r\\nJulius: it needs to change, hope the board sees it\\r\\nLawrence: sooner than later\\r\\nJulius: yeah\\r\\nLawrence: yeah',\n 'summary': \"Lawrence doesn't like the play of Manchester United. He and Julius complain about the team and Mourinho's style.\"}"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"print(samsum_test_dataset.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T15:05:38.893533Z","iopub.execute_input":"2024-11-30T15:05:38.894283Z","iopub.status.idle":"2024-11-30T15:05:38.899654Z","shell.execute_reply.started":"2024-11-30T15:05:38.894254Z","shell.execute_reply":"2024-11-30T15:05:38.898768Z"}},"outputs":[{"name":"stdout","text":"dict_keys(['test'])\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"from transformers import pipeline\n\ntext_summarizer = pipeline(\"summarization\", model=\"facebook/bart-base\", device=0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T15:05:38.939238Z","iopub.execute_input":"2024-11-30T15:05:38.939520Z","iopub.status.idle":"2024-11-30T15:05:40.245694Z","shell.execute_reply.started":"2024-11-30T15:05:38.939492Z","shell.execute_reply":"2024-11-30T15:05:40.244801Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"text_summarizer(samsum_train_dataset[\"train\"][128][\"dialogue\"], max_length=20, min_length=10, do_sample= False )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T15:05:40.247111Z","iopub.execute_input":"2024-11-30T15:05:40.247403Z","iopub.status.idle":"2024-11-30T15:05:40.392474Z","shell.execute_reply.started":"2024-11-30T15:05:40.247358Z","shell.execute_reply":"2024-11-30T15:05:40.391767Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"[{'summary_text': 'Dorothy: Hi! You know what? Ron messaged me again, and'}]"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"# Fine tune the SamSUM model to improve the summarize performance\n# Add the BART tokenizer and model\nfrom transformers import BartForConditionalGeneration, AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\nmodel = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\", dropout=0.3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T15:05:40.393313Z","iopub.execute_input":"2024-11-30T15:05:40.393551Z","iopub.status.idle":"2024-11-30T15:05:41.995300Z","shell.execute_reply.started":"2024-11-30T15:05:40.393528Z","shell.execute_reply":"2024-11-30T15:05:41.994640Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# Remove the icon tag like =), :v\n# Guess the word meaning for the missing character of a word\nimport re\n\ndef preprocess_missingchar_and_icon(sample):\n    def clean_text(text):\n        text = str(text)\n        # Remove icon tags, including the characters inside angled brackets (e.g., <photo>, <emoji>)\n        text = re.sub(r'<.*?>', '', text)\n        \n        # Remove common emoticons or icons like :v, :-), :)\n        text = re.sub(r'(:\\)|:-\\)|:v|:D|<3)', '', text)\n             \n        # Remove extra whitespace caused by the removal of icons\n        text = re.sub(r'\\s+', ' ', text).strip()\n        \n        return text\n    \n    # Apply cleaning to the text and summary fields\n    sample[\"dialogue\"] = clean_text(sample[\"dialogue\"])\n    sample[\"summary\"] = clean_text(sample[\"summary\"])\n    return sample\n\nsamsum_train_dataset_clean = samsum_train_dataset.map(preprocess_missingchar_and_icon)\nsamsum_test_dataset_clean = samsum_test_dataset.map(preprocess_missingchar_and_icon)\nsamsum_validate_dataset_clean = samsum_validate_dataset.map(preprocess_missingchar_and_icon)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T15:05:41.997616Z","iopub.execute_input":"2024-11-30T15:05:41.998212Z","iopub.status.idle":"2024-11-30T15:05:42.014113Z","shell.execute_reply.started":"2024-11-30T15:05:41.998171Z","shell.execute_reply":"2024-11-30T15:05:42.013314Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"def preprocessData(records, tokenizer, max_length_preprocess=128):\n    sources = records[\"dialogue\"]\n    targets = records[\"summary\"]\n\n    input_encoding = tokenizer(sources, max_length=max_length_preprocess*8, padding=\"max_length\", truncation=True)\n    with tokenizer.as_target_tokenizer():\n        output_encoding = tokenizer(targets, max_length=max_length_preprocess, padding=\"max_length\", truncation=True)\n\n    # Return as lists to ensure compatibility with DataLoader\n    return {\n        \"input_ids\": input_encoding[\"input_ids\"],\n        \"attention_mask\": input_encoding[\"attention_mask\"],\n        \"labels\": output_encoding[\"input_ids\"],\n    }\n\ntrain_dataset = samsum_train_dataset_clean[\"train\"].map(lambda x: preprocessData(x, tokenizer), batched=True)\nvalidation_dataset = samsum_validate_dataset_clean[\"validation\"].map(lambda x: preprocessData(x, tokenizer), batched=True)\ntest_dataset = samsum_test_dataset_clean[\"test\"].map(lambda x: preprocessData(x, tokenizer), batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T15:05:42.015163Z","iopub.execute_input":"2024-11-30T15:05:42.015558Z","iopub.status.idle":"2024-11-30T15:05:42.597563Z","shell.execute_reply.started":"2024-11-30T15:05:42.015530Z","shell.execute_reply":"2024-11-30T15:05:42.596737Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/818 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b6ed034660b446a9f4307e644e18f16"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4117: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"# Build the customized DataLoader class for fine-tunning\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import load_dataset\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=8,num_workers=4, shuffle=True)\nvalidation_dataloader = DataLoader(validation_dataset, batch_size=8,num_workers=4)\ntest_dataloader = DataLoader(test_dataset, batch_size=8,num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T15:05:42.598666Z","iopub.execute_input":"2024-11-30T15:05:42.598965Z","iopub.status.idle":"2024-11-30T15:05:42.604987Z","shell.execute_reply.started":"2024-11-30T15:05:42.598938Z","shell.execute_reply":"2024-11-30T15:05:42.604086Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T15:05:42.605986Z","iopub.execute_input":"2024-11-30T15:05:42.606233Z","iopub.status.idle":"2024-11-30T15:05:51.126692Z","shell.execute_reply.started":"2024-11-30T15:05:42.606208Z","shell.execute_reply":"2024-11-30T15:05:51.125805Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.3)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"from transformers import BartForConditionalGeneration, TrainingArguments, Trainer, EarlyStoppingCallback\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results/pre-trained-model\",\n    evaluation_strategy=\"steps\",  \n    save_strategy=\"steps\", \n    save_steps=500,\n    learning_rate=5e-5,\n    weight_decay= 0.01,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=10,\n    save_total_limit=2,\n    load_best_model_at_end=True,  \n    metric_for_best_model=\"eval_loss\", \n    greater_is_better=False,  \n)\n\n# Initialize the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=validation_dataset,\n    tokenizer=tokenizer,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n)\n\n# Train the model\ntrainer.train()\n\n# Save the fine-tuned model and tokenizer\nmodel.save_pretrained(\"./finetuned_bart_samsum\")\ntokenizer.save_pretrained(\"./finetuned_bart_samsum\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T15:05:51.128379Z","iopub.execute_input":"2024-11-30T15:05:51.128774Z","iopub.status.idle":"2024-11-30T16:32:33.709986Z","shell.execute_reply.started":"2024-11-30T15:05:51.128744Z","shell.execute_reply":"2024-11-30T16:32:33.709170Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6500' max='18420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 6500/18420 1:26:39 < 2:38:57, 1.25 it/s, Epoch 3/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>1.135000</td>\n      <td>0.410469</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.477700</td>\n      <td>0.389774</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.460400</td>\n      <td>0.380804</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.432900</td>\n      <td>0.374556</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.404100</td>\n      <td>0.377255</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.408200</td>\n      <td>0.369926</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.395700</td>\n      <td>0.360668</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.375600</td>\n      <td>0.361912</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.356400</td>\n      <td>0.364814</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.370500</td>\n      <td>0.355772</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.365700</td>\n      <td>0.358135</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.340300</td>\n      <td>0.360560</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.336400</td>\n      <td>0.357938</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2618: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\nThere were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n","output_type":"stream"},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"('./finetuned_bart_samsum/tokenizer_config.json',\n './finetuned_bart_samsum/special_tokens_map.json',\n './finetuned_bart_samsum/vocab.json',\n './finetuned_bart_samsum/merges.txt',\n './finetuned_bart_samsum/added_tokens.json',\n './finetuned_bart_samsum/tokenizer.json')"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"# Evaluate the model\nresults = trainer.evaluate(eval_dataset=validation_dataset)\nprint(results)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T16:32:33.711338Z","iopub.execute_input":"2024-11-30T16:32:33.711727Z","iopub.status.idle":"2024-11-30T16:32:54.662645Z","shell.execute_reply.started":"2024-11-30T16:32:33.711686Z","shell.execute_reply":"2024-11-30T16:32:54.661734Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='103' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [103/103 00:20]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.3557721972465515, 'eval_runtime': 20.9406, 'eval_samples_per_second': 39.063, 'eval_steps_per_second': 4.919, 'epoch': 3.528773072747014}\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"!pip install rouge_score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T16:32:54.664954Z","iopub.execute_input":"2024-11-30T16:32:54.665224Z","iopub.status.idle":"2024-11-30T16:33:02.818844Z","shell.execute_reply.started":"2024-11-30T16:32:54.665197Z","shell.execute_reply":"2024-11-30T16:33:02.817994Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: rouge_score in /opt/conda/lib/python3.10/site-packages (0.1.2)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"# Model evaluating using ROUGE\nfrom evaluate import load\nimport torch\n\n# Load ROUGE metric\nrouge = load(\"rouge\")\n\n# Function to generate predictions\ndef generate_predictions(model, tokenizer, dataset):\n    predictions = []\n    references = []\n\n    for example in dataset:\n        # Prepare the input dialogue\n        inputs = tokenizer(\n            example[\"dialogue\"], \n            return_tensors=\"pt\", \n            max_length=512, \n            truncation=True, \n            padding=\"max_length\"\n        )\n        \n        # Move inputs to GPU if available\n        inputs = {k: v.to(\"cuda\") for k, v in inputs.items()} if torch.cuda.is_available() else inputs\n        \n        # Generate summary\n        with torch.no_grad():\n            outputs = model.generate(\n                input_ids=inputs[\"input_ids\"], \n                attention_mask=inputs[\"attention_mask\"], \n                max_length=128, \n                min_length=30, \n                do_sample=False\n            )\n        \n        # Decode the generated summary\n        generated_summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n        \n        # Append generated summary and reference summary\n        predictions.append(generated_summary)\n        references.append(example[\"summary\"])\n    \n    return predictions, references\n\n# Generate predictions and references\ntest_predictions, test_references = generate_predictions(model, tokenizer, validation_dataloader)\n\n# Compute ROUGE scores\nrouge_results = rouge.compute(predictions=test_predictions, references=test_references)\n\n# Print ROUGE scores\nprint(\"ROUGE Scores:\")\nfor key, value in rouge_results.items():\n    print(f\"{key}: {value:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T16:33:02.820272Z","iopub.execute_input":"2024-11-30T16:33:02.820589Z","iopub.status.idle":"2024-11-30T16:36:53.578188Z","shell.execute_reply.started":"2024-11-30T16:33:02.820561Z","shell.execute_reply":"2024-11-30T16:36:53.577230Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"ROUGE Scores:\nrouge1: 0.4504\nrouge2: 0.2175\nrougeL: 0.3650\nrougeLsum: 0.3643\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"#Load the TweetSum dataset\nfrom datasets import load_dataset\n\ntweetsum_train = load_dataset(\"csv\", data_files={\"train\": \"/kaggle/input/tweetsum/tweetsum_train.csv\"})\ntweetsum_test = load_dataset(\"csv\", data_files={\"test\": \"/kaggle/input/tweetsum/tweetsum_test.csv\"})\ntweetsum_validate = load_dataset(\"csv\", data_files={\"validation\": \"/kaggle/input/tweetsum/tweetsum_valid.csv\"})\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T16:36:53.579457Z","iopub.execute_input":"2024-11-30T16:36:53.579757Z","iopub.status.idle":"2024-11-30T16:36:53.961673Z","shell.execute_reply.started":"2024-11-30T16:36:53.579730Z","shell.execute_reply":"2024-11-30T16:36:53.961058Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"tweetsum_train[\"train\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T16:36:53.962728Z","iopub.execute_input":"2024-11-30T16:36:53.963065Z","iopub.status.idle":"2024-11-30T16:36:53.969720Z","shell.execute_reply.started":"2024-11-30T16:36:53.963025Z","shell.execute_reply":"2024-11-30T16:36:53.968974Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"{'id': 1,\n 'dialogue': ' customer: neither my iPhone nor my Apple Watch are recording my steps/activity, and Health doesnâ€™t recognise either source anymore for some reason. Any ideas?  customer: please read the above. support: Letâ€™s investigate this together. To start, can you tell us the software versions your iPhone and Apple Watch are running currently? customer: My iPhone is on 11.1.2, and my watch is on 4.1. support: Thank you. Have you tried restarting both devices since this started happening? customer: Iâ€™ve restarted both, also un-paired then re-paired the watch. support: Got it. When did you first notice that the two devices were not talking to each other. Do the two devices communicate through other apps such as Messages? customer: Yes, everything seems fine, itâ€™s just Health and activity. support: Letâ€™s move to DM and look into this a bit more. When reaching out in DM, let us know when this first started happening please. For example, did it start after an update or after installing a certain app? ',\n 'summary': 'Customer enquired about his Iphone and Apple watch which is not showing his any steps/activity and health activities. Agent is asking to move to DM and look into it.'}"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"tweetsum_test[\"test\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T16:36:53.970698Z","iopub.execute_input":"2024-11-30T16:36:53.971074Z","iopub.status.idle":"2024-11-30T16:36:53.983123Z","shell.execute_reply.started":"2024-11-30T16:36:53.971019Z","shell.execute_reply":"2024-11-30T16:36:53.982274Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"{'id': 1,\n 'dialogue': \" customer: My watchlist is not updating with new episodes (past couple days).  Any idea why? support: Apologies for the trouble, Norlene! We're looking into this. In the meantime, try navigating to the season / episode manually. customer: Tried logging out/back in, that didnâ€™t help support: Sorry! ðŸ˜” We assure you that our team is working hard to investigate, and we hope to have a fix ready soon! customer: Thank you! Some shows updated overnight, but others did not... support: We definitely understand, Norlene. For now, we recommend checking the show page for these shows as the new eps will be there customer: As of this morning, the problem seems to be resolved. Watchlist updated overnight with all new episodes. Thank you for your attention to this matter! I love Hulu ðŸ’š support: Awesome! That's what we love to hear. If you happen to need anything else, we'll be here to support! ðŸ’š\",\n 'summary': 'Customer is complaining that the watchlist is not updated with new episodes from past two days. Agent informed that the team is working hard to investigate to show new episodes on page.'}"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"tweetsum_validate[\"validation\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T16:36:53.984186Z","iopub.execute_input":"2024-11-30T16:36:53.984550Z","iopub.status.idle":"2024-11-30T16:36:53.994561Z","shell.execute_reply.started":"2024-11-30T16:36:53.984522Z","shell.execute_reply":"2024-11-30T16:36:53.993703Z"}},"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"{'id': 1,\n 'dialogue': ' customer: hey, any explanation why the \"Create similar playlist\" function doesn\\'t work anymore for me? MacBook, v1.0.64.399.g4637b02a. support: Hi there, the cavalry\\'s here! Does logging out, restarting your device, and logging back into Spotify help? Keep us in the loop /JI customer: no, it didn\\'t :( tried everything but I still can\\'t create the playlist. it\\'s not even greyed out but nothing happens after clicking on it. support: Okay. Can we have you try reinstalling the app? To do so, just follow the steps at  Let us know how it goes /JI customer: i tried and it\\'s still the same... moreover, my song history is always empty, so I can\\'t find songs from previous Discover playlists :( support: Does restarting your computer help at all? Also, is the song history you\\'re referring to the History tab on your Play Queue? /MT customer: no, I tried that as well and just reinstalled again - didn\\'t help. yes, that\\'s what I mean. support: Could you DM us your account\\'s email address or username? We\\'ll take a look backstage /MT ',\n 'summary': \"Customer is complaining about unable to create similar playlist so that  function does not  work anymore. Agent says could DM the account's email address or username so that they look backstage.\"}"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"# Preprocessing with the TweetSUM dataset\ntweetsum_train_clean = tweetsum_train.map(preprocess_missingchar_and_icon)\ntweetsum_test_clean = tweetsum_test.map(preprocess_missingchar_and_icon)\ntweetsum_validate_clean = tweetsum_validate.map(preprocess_missingchar_and_icon)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T16:36:53.995732Z","iopub.execute_input":"2024-11-30T16:36:53.996056Z","iopub.status.idle":"2024-11-30T16:36:54.012003Z","shell.execute_reply.started":"2024-11-30T16:36:53.996020Z","shell.execute_reply":"2024-11-30T16:36:54.011282Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"# Load the BART_SamSUM model\n# Load the fine-tuned SAMSum model and tokenizer\nfrom transformers import BartForConditionalGeneration, BartTokenizer\n\nmodel_pretrained = BartForConditionalGeneration.from_pretrained(\"./finetuned_bart_samsum\")\ntokenizer_pretrained = BartTokenizer.from_pretrained(\"./finetuned_bart_samsum\")\nmodel_pretrained.resize_token_embeddings(len(tokenizer_pretrained))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T16:36:54.012985Z","iopub.execute_input":"2024-11-30T16:36:54.013312Z","iopub.status.idle":"2024-11-30T16:36:54.871754Z","shell.execute_reply.started":"2024-11-30T16:36:54.013276Z","shell.execute_reply":"2024-11-30T16:36:54.870858Z"}},"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"BartScaledWordEmbedding(50265, 768, padding_idx=1)"},"metadata":{}}],"execution_count":55},{"cell_type":"code","source":"tweetsum_train_dataset = tweetsum_train_clean[\"train\"].map(lambda x: preprocessData(x, tokenizer), batched=True)\ntweetsum_validation_dataset = tweetsum_validate_clean[\"validation\"].map(lambda x: preprocessData(x, tokenizer), batched=True)\ntweetsum_test_dataset = tweetsum_test_clean[\"test\"].map(lambda x: preprocessData(x, tokenizer), batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T16:36:54.872750Z","iopub.execute_input":"2024-11-30T16:36:54.873020Z","iopub.status.idle":"2024-11-30T16:36:55.079831Z","shell.execute_reply.started":"2024-11-30T16:36:54.872992Z","shell.execute_reply":"2024-11-30T16:36:55.078974Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/110 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e962f8403e8445dd8732553156f5339f"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4117: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"tweetsum_train_dataloader = DataLoader(tweetsum_train_dataset, batch_size=8, shuffle=True)\ntweetsum_validation_dataloader = DataLoader(tweetsum_validation_dataset, batch_size=8)\ntweetsum_test_dataloader = DataLoader(tweetsum_test_dataset, batch_size=8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T16:36:55.080835Z","iopub.execute_input":"2024-11-30T16:36:55.081095Z","iopub.status.idle":"2024-11-30T16:36:55.086405Z","shell.execute_reply.started":"2024-11-30T16:36:55.081067Z","shell.execute_reply":"2024-11-30T16:36:55.085453Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"from transformers import BartForConditionalGeneration, TrainingArguments, Trainer, EarlyStoppingCallback\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results/fine-tuned-model\",\n    evaluation_strategy=\"steps\",  \n    save_strategy=\"steps\",        \n    learning_rate=5e-5,\n    weight_decay= 0.01,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=10,\n    save_total_limit=2,\n    load_best_model_at_end=True,  \n    metric_for_best_model=\"eval_loss\", \n    greater_is_better=False,  \n)\n\n# Initialize the Trainer\ntrainer = Trainer(\n    model=model_pretrained,\n    args=training_args,\n    train_dataset=tweetsum_train_dataset,\n    eval_dataset=tweetsum_validation_dataset,\n    tokenizer=tokenizer_pretrained,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n)\n\n# Train the model\ntrainer.train()\n\n# Save the fine-tuned model and tokenizer\nmodel.save_pretrained(\"./finetuned_bart_tweetsum\")\ntokenizer.save_pretrained(\"./finetuned_bart_tweetsum\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T16:36:55.087415Z","iopub.execute_input":"2024-11-30T16:36:55.087676Z","iopub.status.idle":"2024-11-30T16:50:59.890308Z","shell.execute_reply.started":"2024-11-30T16:36:55.087650Z","shell.execute_reply":"2024-11-30T16:50:59.889416Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1100' max='1100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1100/1100 14:01, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.661900</td>\n      <td>0.644841</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.491600</td>\n      <td>0.625262</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n","output_type":"stream"},{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"('./finetuned_bart_tweetsum/tokenizer_config.json',\n './finetuned_bart_tweetsum/special_tokens_map.json',\n './finetuned_bart_tweetsum/vocab.json',\n './finetuned_bart_tweetsum/merges.txt',\n './finetuned_bart_tweetsum/added_tokens.json',\n './finetuned_bart_tweetsum/tokenizer.json')"},"metadata":{}}],"execution_count":58},{"cell_type":"code","source":"# Model evaluating using ROUGE\nfrom evaluate import load\nimport torch\n\n# Load ROUGE metric\nrouge = load(\"rouge\")\n\n# Function to generate predictions\ndef generate_predictions(model, tokenizer, dataset):\n    predictions = []\n    references = []\n\n    for example in dataset:\n        # Prepare the input dialogue\n        inputs = tokenizer(\n            example[\"dialogue\"], \n            return_tensors=\"pt\", \n            max_length=512, \n            truncation=True, \n            padding=\"max_length\"\n        )\n        \n        # Move inputs to GPU if available\n        inputs = {k: v.to(\"cuda\") for k, v in inputs.items()} if torch.cuda.is_available() else inputs\n        \n        # Generate summary\n        with torch.no_grad():\n            outputs = model.generate(\n                input_ids=inputs[\"input_ids\"], \n                attention_mask=inputs[\"attention_mask\"], \n                max_length=128, \n                min_length=30, \n                do_sample=False\n            )\n        \n        # Decode the generated summary\n        generated_summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n        \n        # Append generated summary and reference summary\n        predictions.append(generated_summary)\n        references.append(example[\"summary\"])\n    \n    return predictions, references\n\n# Generate predictions and references\ntest_predictions, test_references = generate_predictions(model_pretrained, tokenizer_pretrained, tweetsum_validation_dataloader)\n\n# Compute ROUGE scores\nrouge_results = rouge.compute(predictions=test_predictions, references=test_references)\n\n# Print ROUGE scores\nprint(\"ROUGE Scores:\")\nfor key, value in rouge_results.items():\n    print(f\"{key}: {value:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T16:50:59.891325Z","iopub.execute_input":"2024-11-30T16:50:59.891626Z","iopub.status.idle":"2024-11-30T16:51:16.604180Z","shell.execute_reply.started":"2024-11-30T16:50:59.891599Z","shell.execute_reply":"2024-11-30T16:51:16.603167Z"}},"outputs":[{"name":"stdout","text":"ROUGE Scores:\nrouge1: 0.4810\nrouge2: 0.2222\nrougeL: 0.3954\nrougeLsum: 0.3935\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}