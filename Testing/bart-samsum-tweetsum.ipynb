{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-26T17:04:01.524420Z",
     "iopub.status.busy": "2024-11-26T17:04:01.523762Z",
     "iopub.status.idle": "2024-11-26T17:04:04.106596Z",
     "shell.execute_reply": "2024-11-26T17:04:04.105949Z",
     "shell.execute_reply.started": "2024-11-26T17:04:01.524382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c203e1f109194bad8da7a34dadc464b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2c08ede83c4716b803625830827f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e0932b6f47442cbd68eeebf72f09bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "samsum_train_dataset = load_dataset(\"csv\", data_files={\"train\": \"/kaggle/input/samsum-dataset-text-summarization/samsum-test.csv\"})\n",
    "samsum_test_dataset = load_dataset(\"csv\", data_files={\"test\": \"/kaggle/input/samsum-dataset-text-summarization/samsum-test.csv\"})\n",
    "samsum_validate_dataset = load_dataset(\"csv\", data_files={\"validation\": \"/kaggle/input/samsum-dataset-text-summarization/samsum-validation.csv\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:04:05.600831Z",
     "iopub.status.busy": "2024-11-26T17:04:05.600481Z",
     "iopub.status.idle": "2024-11-26T17:04:05.609616Z",
     "shell.execute_reply": "2024-11-26T17:04:05.608859Z",
     "shell.execute_reply.started": "2024-11-26T17:04:05.600782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '13729565',\n",
       " 'dialogue': \"Eric: MACHINE!\\r\\nRob: That's so gr8!\\r\\nEric: I know! And shows how Americans see Russian ;)\\r\\nRob: And it's really funny!\\r\\nEric: I know! I especially like the train part!\\r\\nRob: Hahaha! No one talks to the machine like that!\\r\\nEric: Is this his only stand-up?\\r\\nRob: Idk. I'll check.\\r\\nEric: Sure.\\r\\nRob: Turns out no! There are some of his stand-ups on youtube.\\r\\nEric: Gr8! I'll watch them now!\\r\\nRob: Me too!\\r\\nEric: MACHINE!\\r\\nRob: MACHINE!\\r\\nEric: TTYL?\\r\\nRob: Sure :)\",\n",
       " 'summary': 'Eric and Rob are going to watch a stand-up on youtube.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samsum_train_dataset[\"train\"][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:04:06.100858Z",
     "iopub.status.busy": "2024-11-26T17:04:06.100526Z",
     "iopub.status.idle": "2024-11-26T17:04:06.105582Z",
     "shell.execute_reply": "2024-11-26T17:04:06.104684Z",
     "shell.execute_reply.started": "2024-11-26T17:04:06.100829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['test'])\n"
     ]
    }
   ],
   "source": [
    "print(samsum_test_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:04:06.137671Z",
     "iopub.status.busy": "2024-11-26T17:04:06.136934Z",
     "iopub.status.idle": "2024-11-26T17:04:31.458407Z",
     "shell.execute_reply": "2024-11-26T17:04:31.457602Z",
     "shell.execute_reply.started": "2024-11-26T17:04:06.137641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcae22b6c4e64e1c80f80c3e19e8b6d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89058e01f67d4c0a9399bbc613314126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac30acb6674458da3a8a19dd9a723e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f0c2b20fca44a88823a9023f0154f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e874637ebb7d4895b36931ff704936b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "text_summarizer = pipeline(\"summarization\", model=\"facebook/bart-base\", device=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:04:31.461252Z",
     "iopub.status.busy": "2024-11-26T17:04:31.460137Z",
     "iopub.status.idle": "2024-11-26T17:04:32.376877Z",
     "shell.execute_reply": "2024-11-26T17:04:32.375927Z",
     "shell.execute_reply.started": "2024-11-26T17:04:31.461207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Paul: hey Matthew did you find anyone to couch the game Saturday?Matthew: hey'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_summarizer(samsum_train_dataset[\"train\"][128][\"dialogue\"], max_length=20, min_length=10, do_sample= False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:04:32.378777Z",
     "iopub.status.busy": "2024-11-26T17:04:32.378417Z",
     "iopub.status.idle": "2024-11-26T17:04:35.127425Z",
     "shell.execute_reply": "2024-11-26T17:04:35.126148Z",
     "shell.execute_reply.started": "2024-11-26T17:04:32.378737Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fine tune the SamSUM model to improve the summarize performance\n",
    "# Add the BART tokenizer and model\n",
    "from transformers import BartForConditionalGeneration, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\", dropout=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:04:35.129597Z",
     "iopub.status.busy": "2024-11-26T17:04:35.129309Z",
     "iopub.status.idle": "2024-11-26T17:04:35.459608Z",
     "shell.execute_reply": "2024-11-26T17:04:35.458759Z",
     "shell.execute_reply.started": "2024-11-26T17:04:35.129561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342c9646f0ff456b9ae3ce9b1c1cf28f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091a13a433bd4904b1eb346414cf8a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d3e67e3111451eb216d8675890c8a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove the icon tag like =), :v\n",
    "# Guess the word meaning for the missing character of a word\n",
    "import re\n",
    "\n",
    "def preprocess_missingchar_and_icon(sample):\n",
    "    def clean_text(text):\n",
    "        # Remove icon tags, including the characters inside angled brackets (e.g., <photo>, <emoji>)\n",
    "        text = re.sub(r'<.*?>', '', text)\n",
    "        \n",
    "        # Remove common emoticons or icons like :v, :-), :)\n",
    "        text = re.sub(r'(:\\)|:-\\)|:v|:D|<3)', '', text)\n",
    "             \n",
    "        # Remove extra whitespace caused by the removal of icons\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    # Apply cleaning to the text and summary fields\n",
    "    sample[\"dialogue\"] = clean_text(sample[\"dialogue\"])\n",
    "    sample[\"summary\"] = clean_text(sample[\"summary\"])\n",
    "    return sample\n",
    "\n",
    "samsum_train_dataset_clean = samsum_train_dataset.map(preprocess_missingchar_and_icon)\n",
    "samsum_test_dataset_clean = samsum_test_dataset.map(preprocess_missingchar_and_icon)\n",
    "samsum_validate_dataset_clean = samsum_validate_dataset.map(preprocess_missingchar_and_icon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:04:35.460841Z",
     "iopub.status.busy": "2024-11-26T17:04:35.460599Z",
     "iopub.status.idle": "2024-11-26T17:04:38.684503Z",
     "shell.execute_reply": "2024-11-26T17:04:38.683713Z",
     "shell.execute_reply.started": "2024-11-26T17:04:35.460816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d83ce6b1f1d44d68a8557b5f402f4a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4117: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a16b14769dd482a8481735750085699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c10105aeee4f88ba2b0a279c5fc43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocessData(records, tokenizer, max_length_preprocess=128):\n",
    "    sources = records[\"dialogue\"]\n",
    "    targets = records[\"summary\"]\n",
    "\n",
    "    input_encoding = tokenizer(sources, max_length=max_length_preprocess*8, padding=\"max_length\", truncation=True)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        output_encoding = tokenizer(targets, max_length=max_length_preprocess, padding=\"max_length\", truncation=True)\n",
    "\n",
    "    # Return as lists to ensure compatibility with DataLoader\n",
    "    return {\n",
    "        \"input_ids\": input_encoding[\"input_ids\"],\n",
    "        \"attention_mask\": input_encoding[\"attention_mask\"],\n",
    "        \"labels\": output_encoding[\"input_ids\"],\n",
    "    }\n",
    "\n",
    "train_dataset = samsum_train_dataset_clean[\"train\"].map(lambda x: preprocessData(x, tokenizer), batched=True)\n",
    "validation_dataset = samsum_validate_dataset_clean[\"validation\"].map(lambda x: preprocessData(x, tokenizer), batched=True)\n",
    "test_dataset = samsum_test_dataset_clean[\"test\"].map(lambda x: preprocessData(x, tokenizer), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:04:38.685707Z",
     "iopub.status.busy": "2024-11-26T17:04:38.685441Z",
     "iopub.status.idle": "2024-11-26T17:04:38.690632Z",
     "shell.execute_reply": "2024-11-26T17:04:38.689716Z",
     "shell.execute_reply.started": "2024-11-26T17:04:38.685682Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build the customized DataLoader class for fine-tunning\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=8)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:04:38.692127Z",
     "iopub.status.busy": "2024-11-26T17:04:38.691804Z",
     "iopub.status.idle": "2024-11-26T17:04:48.352588Z",
     "shell.execute_reply": "2024-11-26T17:04:48.351640Z",
     "shell.execute_reply.started": "2024-11-26T17:04:38.692099Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:04:48.354378Z",
     "iopub.status.busy": "2024-11-26T17:04:48.354075Z",
     "iopub.status.idle": "2024-11-26T17:19:15.251380Z",
     "shell.execute_reply": "2024-11-26T17:19:15.250456Z",
     "shell.execute_reply.started": "2024-11-26T17:04:48.354346Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475c0d12d3e241a2bef8d4377910eda1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112949311110596, max=1.0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241126_170535-9n8l6b5y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/zhukov01/huggingface/runs/9n8l6b5y' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/zhukov01/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/zhukov01/huggingface' target=\"_blank\">https://wandb.ai/zhukov01/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/zhukov01/huggingface/runs/9n8l6b5y' target=\"_blank\">https://wandb.ai/zhukov01/huggingface/runs/9n8l6b5y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1030' max='1030' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1030/1030 13:33, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.093400</td>\n",
       "      <td>0.416001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.302100</td>\n",
       "      <td>0.424176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2618: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n",
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./finetuned_bart_samsum/tokenizer_config.json',\n",
       " './finetuned_bart_samsum/special_tokens_map.json',\n",
       " './finetuned_bart_samsum/vocab.json',\n",
       " './finetuned_bart_samsum/merges.txt',\n",
       " './finetuned_bart_samsum/added_tokens.json',\n",
       " './finetuned_bart_samsum/tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"steps\",  \n",
    "    save_strategy=\"steps\",        \n",
    "    learning_rate=5e-5,\n",
    "    weight_decay= 0.01,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,  \n",
    "    metric_for_best_model=\"eval_loss\", \n",
    "    greater_is_better=False,  \n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained(\"./finetuned_bart_samsum\")\n",
    "tokenizer.save_pretrained(\"./finetuned_bart_samsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:19:15.252784Z",
     "iopub.status.busy": "2024-11-26T17:19:15.252479Z",
     "iopub.status.idle": "2024-11-26T17:19:36.074706Z",
     "shell.execute_reply": "2024-11-26T17:19:36.073706Z",
     "shell.execute_reply.started": "2024-11-26T17:19:15.252756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='103' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [103/103 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2509564757347107, 'eval_runtime': 20.8104, 'eval_samples_per_second': 39.355, 'eval_steps_per_second': 4.949, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:19:36.079225Z",
     "iopub.status.busy": "2024-11-26T17:19:36.078939Z",
     "iopub.status.idle": "2024-11-26T17:19:46.770638Z",
     "shell.execute_reply": "2024-11-26T17:19:46.769311Z",
     "shell.execute_reply.started": "2024-11-26T17:19:36.079196Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=b0bb208e6825f4f2aad484f9d5aa04bb5a6f1cf135f0526bcafdbfb2fa4a708a\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:19:46.772778Z",
     "iopub.status.busy": "2024-11-26T17:19:46.772333Z",
     "iopub.status.idle": "2024-11-26T17:21:26.346366Z",
     "shell.execute_reply": "2024-11-26T17:21:26.345444Z",
     "shell.execute_reply.started": "2024-11-26T17:19:46.772742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2fcdf10d72a47008aa1ae220df9a9ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores:\n",
      "rouge1: 0.4234\n",
      "rouge2: 0.1938\n",
      "rougeL: 0.3272\n",
      "rougeLsum: 0.3273\n"
     ]
    }
   ],
   "source": [
    "# Model evaluating using ROUGE\n",
    "from evaluate import load\n",
    "import torch\n",
    "\n",
    "# Load ROUGE metric\n",
    "rouge = load(\"rouge\")\n",
    "\n",
    "# Function to generate predictions\n",
    "def generate_predictions(model, tokenizer, dataset):\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    for example in dataset:\n",
    "        # Prepare the input dialogue\n",
    "        inputs = tokenizer(\n",
    "            example[\"dialogue\"], \n",
    "            return_tensors=\"pt\", \n",
    "            max_length=512, \n",
    "            truncation=True, \n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "        \n",
    "        # Move inputs to GPU if available\n",
    "        inputs = {k: v.to(\"cuda\") for k, v in inputs.items()} if torch.cuda.is_available() else inputs\n",
    "        \n",
    "        # Generate summary\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                input_ids=inputs[\"input_ids\"], \n",
    "                attention_mask=inputs[\"attention_mask\"], \n",
    "                max_length=128, \n",
    "                min_length=30, \n",
    "                do_sample=False\n",
    "            )\n",
    "        \n",
    "        # Decode the generated summary\n",
    "        generated_summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Append generated summary and reference summary\n",
    "        predictions.append(generated_summary)\n",
    "        references.append(example[\"summary\"])\n",
    "    \n",
    "    return predictions, references\n",
    "\n",
    "# Generate predictions and references\n",
    "test_predictions, test_references = generate_predictions(model, tokenizer, validation_dataloader)\n",
    "\n",
    "# Compute ROUGE scores\n",
    "rouge_results = rouge.compute(predictions=test_predictions, references=test_references)\n",
    "\n",
    "# Print ROUGE scores\n",
    "print(\"ROUGE Scores:\")\n",
    "for key, value in rouge_results.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:21:26.348357Z",
     "iopub.status.busy": "2024-11-26T17:21:26.347612Z",
     "iopub.status.idle": "2024-11-26T17:21:27.519194Z",
     "shell.execute_reply": "2024-11-26T17:21:27.518211Z",
     "shell.execute_reply.started": "2024-11-26T17:21:26.348294Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e780c81c064424a97621cd62c4169ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d6bc716f60948b78159a3e841225262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb010d9d134044da8d27d960f731f184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load the TweetSum dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "tweetsum_train = load_dataset(\"csv\", data_files={\"train\": \"/kaggle/input/tweetsum/tweetsum_train.csv\"})\n",
    "tweetsum_test = load_dataset(\"csv\", data_files={\"test\": \"/kaggle/input/tweetsum/tweetsum_test.csv\"})\n",
    "tweetsum_validate = load_dataset(\"csv\", data_files={\"validation\": \"/kaggle/input/tweetsum/tweetsum_valid.csv\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:21:27.520488Z",
     "iopub.status.busy": "2024-11-26T17:21:27.520237Z",
     "iopub.status.idle": "2024-11-26T17:21:27.527770Z",
     "shell.execute_reply": "2024-11-26T17:21:27.526964Z",
     "shell.execute_reply.started": "2024-11-26T17:21:27.520461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'dialogue': ' customer: neither my iPhone nor my Apple Watch are recording my steps/activity, and Health doesn‚Äôt recognise either source anymore for some reason. Any ideas?  customer: please read the above. support: Let‚Äôs investigate this together. To start, can you tell us the software versions your iPhone and Apple Watch are running currently? customer: My iPhone is on 11.1.2, and my watch is on 4.1. support: Thank you. Have you tried restarting both devices since this started happening? customer: I‚Äôve restarted both, also un-paired then re-paired the watch. support: Got it. When did you first notice that the two devices were not talking to each other. Do the two devices communicate through other apps such as Messages? customer: Yes, everything seems fine, it‚Äôs just Health and activity. support: Let‚Äôs move to DM and look into this a bit more. When reaching out in DM, let us know when this first started happening please. For example, did it start after an update or after installing a certain app? ',\n",
       " 'summary': 'Customer enquired about his Iphone and Apple watch which is not showing his any steps/activity and health activities. Agent is asking to move to DM and look into it.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsum_train[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:21:27.528990Z",
     "iopub.status.busy": "2024-11-26T17:21:27.528694Z",
     "iopub.status.idle": "2024-11-26T17:21:27.540501Z",
     "shell.execute_reply": "2024-11-26T17:21:27.539673Z",
     "shell.execute_reply.started": "2024-11-26T17:21:27.528963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'dialogue': \" customer: My watchlist is not updating with new episodes (past couple days).  Any idea why? support: Apologies for the trouble, Norlene! We're looking into this. In the meantime, try navigating to the season / episode manually. customer: Tried logging out/back in, that didn‚Äôt help support: Sorry! üòî We assure you that our team is working hard to investigate, and we hope to have a fix ready soon! customer: Thank you! Some shows updated overnight, but others did not... support: We definitely understand, Norlene. For now, we recommend checking the show page for these shows as the new eps will be there customer: As of this morning, the problem seems to be resolved. Watchlist updated overnight with all new episodes. Thank you for your attention to this matter! I love Hulu üíö support: Awesome! That's what we love to hear. If you happen to need anything else, we'll be here to support! üíö\",\n",
       " 'summary': 'Customer is complaining that the watchlist is not updated with new episodes from past two days. Agent informed that the team is working hard to investigate to show new episodes on page.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsum_test[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:21:27.542565Z",
     "iopub.status.busy": "2024-11-26T17:21:27.541611Z",
     "iopub.status.idle": "2024-11-26T17:21:27.550544Z",
     "shell.execute_reply": "2024-11-26T17:21:27.549682Z",
     "shell.execute_reply.started": "2024-11-26T17:21:27.542519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'dialogue': ' customer: hey, any explanation why the \"Create similar playlist\" function doesn\\'t work anymore for me? MacBook, v1.0.64.399.g4637b02a. support: Hi there, the cavalry\\'s here! Does logging out, restarting your device, and logging back into Spotify help? Keep us in the loop /JI customer: no, it didn\\'t :( tried everything but I still can\\'t create the playlist. it\\'s not even greyed out but nothing happens after clicking on it. support: Okay. Can we have you try reinstalling the app? To do so, just follow the steps at  Let us know how it goes /JI customer: i tried and it\\'s still the same... moreover, my song history is always empty, so I can\\'t find songs from previous Discover playlists :( support: Does restarting your computer help at all? Also, is the song history you\\'re referring to the History tab on your Play Queue? /MT customer: no, I tried that as well and just reinstalled again - didn\\'t help. yes, that\\'s what I mean. support: Could you DM us your account\\'s email address or username? We\\'ll take a look backstage /MT ',\n",
       " 'summary': \"Customer is complaining about unable to create similar playlist so that  function does not  work anymore. Agent says could DM the account's email address or username so that they look backstage.\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsum_validate[\"validation\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:21:27.551796Z",
     "iopub.status.busy": "2024-11-26T17:21:27.551544Z",
     "iopub.status.idle": "2024-11-26T17:21:27.819311Z",
     "shell.execute_reply": "2024-11-26T17:21:27.818401Z",
     "shell.execute_reply.started": "2024-11-26T17:21:27.551772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab03648d90f442faaf3b5126adbc3196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/879 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb6bf71496542e7bfdca49dae85e05b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9052c285f3a450f8f6610d6f4a47f75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocessing with the TweetSUM dataset\n",
    "tweetsum_train_clean = tweetsum_train.map(preprocess_missingchar_and_icon)\n",
    "tweetsum_test_clean = tweetsum_test.map(preprocess_missingchar_and_icon)\n",
    "tweetsum_validate_clean = tweetsum_validate.map(preprocess_missingchar_and_icon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:21:27.820662Z",
     "iopub.status.busy": "2024-11-26T17:21:27.820403Z",
     "iopub.status.idle": "2024-11-26T17:21:28.672602Z",
     "shell.execute_reply": "2024-11-26T17:21:28.671853Z",
     "shell.execute_reply.started": "2024-11-26T17:21:27.820636Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the BART_SamSUM model\n",
    "# Load the fine-tuned SAMSum model and tokenizer\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "model_pretrained = BartForConditionalGeneration.from_pretrained(\"./finetuned_bart_samsum\")\n",
    "tokenizer_pretrained = BartTokenizer.from_pretrained(\"./finetuned_bart_samsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:21:28.673845Z",
     "iopub.status.busy": "2024-11-26T17:21:28.673589Z",
     "iopub.status.idle": "2024-11-26T17:21:29.638675Z",
     "shell.execute_reply": "2024-11-26T17:21:29.637796Z",
     "shell.execute_reply.started": "2024-11-26T17:21:28.673819Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ac8b2d38c646adb1212d92a3bced44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/879 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4117: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4e1f8345ba4f22a6954c7b3cb424ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4d536d661a48bfabe5b299e39ada63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweetsum_train_dataset = tweetsum_train_clean[\"train\"].map(lambda x: preprocessData(x, tokenizer), batched=True)\n",
    "tweetsum_validation_dataset = tweetsum_validate_clean[\"validation\"].map(lambda x: preprocessData(x, tokenizer), batched=True)\n",
    "tweetsum_test_dataset = tweetsum_test_clean[\"test\"].map(lambda x: preprocessData(x, tokenizer), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:21:29.640371Z",
     "iopub.status.busy": "2024-11-26T17:21:29.640006Z",
     "iopub.status.idle": "2024-11-26T17:21:29.646737Z",
     "shell.execute_reply": "2024-11-26T17:21:29.645710Z",
     "shell.execute_reply.started": "2024-11-26T17:21:29.640315Z"
    }
   },
   "outputs": [],
   "source": [
    "tweetsum_train_dataloader = DataLoader(tweetsum_train_dataset, batch_size=8, shuffle=True)\n",
    "tweetsum_validation_dataloader = DataLoader(tweetsum_validation_dataset, batch_size=8)\n",
    "tweetsum_test_dataloader = DataLoader(tweetsum_test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:21:29.648673Z",
     "iopub.status.busy": "2024-11-26T17:21:29.648402Z",
     "iopub.status.idle": "2024-11-26T17:35:29.959378Z",
     "shell.execute_reply": "2024-11-26T17:35:29.958559Z",
     "shell.execute_reply.started": "2024-11-26T17:21:29.648646Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1100' max='1100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1100/1100 13:57, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.701100</td>\n",
       "      <td>0.647596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.526400</td>\n",
       "      <td>0.627805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./finetuned_bart_tweetsum/tokenizer_config.json',\n",
       " './finetuned_bart_tweetsum/special_tokens_map.json',\n",
       " './finetuned_bart_tweetsum/vocab.json',\n",
       " './finetuned_bart_tweetsum/merges.txt',\n",
       " './finetuned_bart_tweetsum/added_tokens.json',\n",
       " './finetuned_bart_tweetsum/tokenizer.json')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"steps\",  \n",
    "    save_strategy=\"steps\",        \n",
    "    learning_rate=5e-5,\n",
    "    weight_decay= 0.01,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,  \n",
    "    metric_for_best_model=\"eval_loss\", \n",
    "    greater_is_better=False,  \n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model_pretrained,\n",
    "    args=training_args,\n",
    "    train_dataset=tweetsum_train_dataset,\n",
    "    eval_dataset=tweetsum_validation_dataset,\n",
    "    tokenizer=tokenizer_pretrained,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained(\"./finetuned_bart_tweetsum\")\n",
    "tokenizer.save_pretrained(\"./finetuned_bart_tweetsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T17:35:29.961087Z",
     "iopub.status.busy": "2024-11-26T17:35:29.960714Z",
     "iopub.status.idle": "2024-11-26T17:35:53.840872Z",
     "shell.execute_reply": "2024-11-26T17:35:53.840035Z",
     "shell.execute_reply.started": "2024-11-26T17:35:29.961047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores:\n",
      "rouge1: 0.4495\n",
      "rouge2: 0.2005\n",
      "rougeL: 0.3739\n",
      "rougeLsum: 0.3707\n"
     ]
    }
   ],
   "source": [
    "# Model evaluating using ROUGE\n",
    "from evaluate import load\n",
    "import torch\n",
    "\n",
    "# Load ROUGE metric\n",
    "rouge = load(\"rouge\")\n",
    "\n",
    "# Function to generate predictions\n",
    "def generate_predictions(model, tokenizer, dataset):\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    for example in dataset:\n",
    "        # Prepare the input dialogue\n",
    "        inputs = tokenizer(\n",
    "            example[\"dialogue\"], \n",
    "            return_tensors=\"pt\", \n",
    "            max_length=512, \n",
    "            truncation=True, \n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "        \n",
    "        # Move inputs to GPU if available\n",
    "        inputs = {k: v.to(\"cuda\") for k, v in inputs.items()} if torch.cuda.is_available() else inputs\n",
    "        \n",
    "        # Generate summary\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                input_ids=inputs[\"input_ids\"], \n",
    "                attention_mask=inputs[\"attention_mask\"], \n",
    "                max_length=128, \n",
    "                min_length=30, \n",
    "                do_sample=False\n",
    "            )\n",
    "        \n",
    "        # Decode the generated summary\n",
    "        generated_summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Append generated summary and reference summary\n",
    "        predictions.append(generated_summary)\n",
    "        references.append(example[\"summary\"])\n",
    "    \n",
    "    return predictions, references\n",
    "\n",
    "# Generate predictions and references\n",
    "test_predictions, test_references = generate_predictions(model_pretrained, tokenizer_pretrained, tweetsum_validation_dataloader)\n",
    "\n",
    "# Compute ROUGE scores\n",
    "rouge_results = rouge.compute(predictions=test_predictions, references=test_references)\n",
    "\n",
    "# Print ROUGE scores\n",
    "print(\"ROUGE Scores:\")\n",
    "for key, value in rouge_results.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3438844,
     "sourceId": 6004344,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6155682,
     "sourceId": 10000750,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6170631,
     "sourceId": 10021056,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
