{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10031025,"sourceType":"datasetVersion","datasetId":6178036}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Load the TweetSum dataset\nfrom datasets import load_dataset\n\ntweetsum_train = load_dataset(\"csv\", data_files={\"train\": \"/kaggle/input/tweetsum1/tweetsum_train.csv\"})\ntweetsum_test = load_dataset(\"csv\", data_files={\"test\": \"/kaggle/input/tweetsum1/tweetsum_test.csv\"})\ntweetsum_validate = load_dataset(\"csv\", data_files={\"validation\": \"/kaggle/input/tweetsum1/tweetsum_valid.csv\"})\n\n","metadata":{"_uuid":"ed3020e8-5d67-4fcc-b564-08c8cd385590","_cell_guid":"97df1bdf-9cc7-4639-bde8-c83a973b00f1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-11-27T14:53:02.012701Z","iopub.execute_input":"2024-11-27T14:53:02.013392Z","iopub.status.idle":"2024-11-27T14:53:03.995123Z","shell.execute_reply.started":"2024-11-27T14:53:02.013357Z","shell.execute_reply":"2024-11-27T14:53:03.994132Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33b7f7f0d7704d2989f20ebac1651e30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f7746602ed8412e953d8987f24c5e62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ae079af368b4c5eabf0bfc858205fdc"}},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"from transformers import BartForConditionalGeneration, AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\nmodel = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\", dropout=0.3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:53:03.996879Z","iopub.execute_input":"2024-11-27T14:53:03.997297Z","iopub.status.idle":"2024-11-27T14:53:13.480937Z","shell.execute_reply.started":"2024-11-27T14:53:03.997266Z","shell.execute_reply":"2024-11-27T14:53:13.479960Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f14a6df7a55043899031aa43f7782d12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"805b2f0e480c4a1d9f3c5ad307f47159"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3006c4275c464c2d97af8f7bf03bbad2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fd03a1c701e4378a1b680f7170db1d1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90450ae4a27c45ea930549ca4d135293"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# Remove the icon tag like =), :v\n# Guess the word meaning for the missing character of a word\nimport re\n\ndef preprocess_missingchar_and_icon(sample):\n    def clean_text(text):\n        # Remove icon tags, including the characters inside angled brackets (e.g., <photo>, <emoji>)\n        text = re.sub(r'<.*?>', '', text)\n        \n        # Remove common emoticons or icons like :v, :-), :)\n        text = re.sub(r'(:\\)|:-\\)|:v|:D|<3)', '', text)\n             \n        # Remove extra whitespace caused by the removal of icons\n        text = re.sub(r'\\s+', ' ', text).strip()\n        \n        return text\n    \n    # Apply cleaning to the text and summary fields\n    sample[\"dialogue\"] = clean_text(sample[\"dialogue\"])\n    sample[\"summary\"] = clean_text(sample[\"summary\"])\n    return sample\n\n# Preprocessing with the TweetSUM dataset\ntweetsum_train_clean = tweetsum_train.map(preprocess_missingchar_and_icon)\ntweetsum_test_clean = tweetsum_test.map(preprocess_missingchar_and_icon)\ntweetsum_validate_clean = tweetsum_validate.map(preprocess_missingchar_and_icon)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:53:13.482152Z","iopub.execute_input":"2024-11-27T14:53:13.482593Z","iopub.status.idle":"2024-11-27T14:53:13.728678Z","shell.execute_reply.started":"2024-11-27T14:53:13.482560Z","shell.execute_reply":"2024-11-27T14:53:13.727765Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/879 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21b5ae17e446433ba028bd8ba3e10309"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/110 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a818976d37f5467993982ffcd6cafc35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/110 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33482f2713924a5a9e7f3db909c557c9"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"def preprocessData(records, tokenizer, max_length_preprocess=128):\n    sources = records[\"dialogue\"]\n    targets = records[\"summary\"]\n\n    input_encoding = tokenizer(sources, max_length=max_length_preprocess*8, padding=\"max_length\", truncation=True)\n    with tokenizer.as_target_tokenizer():\n        output_encoding = tokenizer(targets, max_length=max_length_preprocess, padding=\"max_length\", truncation=True)\n\n    # Return as lists to ensure compatibility with DataLoader\n    return {\n        \"input_ids\": input_encoding[\"input_ids\"],\n        \"attention_mask\": input_encoding[\"attention_mask\"],\n        \"labels\": output_encoding[\"input_ids\"],\n    }\ntweetsum_train_dataset = tweetsum_train_clean[\"train\"].map(lambda x: preprocessData(x, tokenizer), batched=True)\ntweetsum_validation_dataset = tweetsum_validate_clean[\"validation\"].map(lambda x: preprocessData(x, tokenizer), batched=True)\ntweetsum_test_dataset = tweetsum_test_clean[\"test\"].map(lambda x: preprocessData(x, tokenizer), batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:53:13.730549Z","iopub.execute_input":"2024-11-27T14:53:13.730882Z","iopub.status.idle":"2024-11-27T14:53:14.838947Z","shell.execute_reply.started":"2024-11-27T14:53:13.730840Z","shell.execute_reply":"2024-11-27T14:53:14.837988Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/879 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fad2be557f44c7cb772288b8dc31ed0"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4117: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/110 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7cf230718784c29be09f6430836420b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/110 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"108232ffcea84e7384aa95b2ab3d102e"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"from transformers import BartForConditionalGeneration, TrainingArguments, Trainer, EarlyStoppingCallback\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results/tweetsum-finetuned\",\n    evaluation_strategy=\"steps\",  \n    save_strategy=\"steps\",        \n    learning_rate=5e-5,\n    weight_decay= 0.01,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=10,\n    save_total_limit=2,\n    load_best_model_at_end=True,  \n    metric_for_best_model=\"eval_loss\", \n    greater_is_better=False,  \n)\n\n# Initialize the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tweetsum_train_dataset,\n    eval_dataset=tweetsum_validation_dataset,\n    tokenizer=tokenizer,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n)\n\n# Train the model\ntrainer.train()\n\n# Save the fine-tuned model and tokenizer\nmodel.save_pretrained(\"./finetuned_bart_tweetsum1\")\ntokenizer.save_pretrained(\"./finetuned_bart_tweetsum1\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T14:53:14.839922Z","iopub.execute_input":"2024-11-27T14:53:14.840173Z","iopub.status.idle":"2024-11-27T15:08:07.039775Z","shell.execute_reply.started":"2024-11-27T14:53:14.840148Z","shell.execute_reply":"2024-11-27T15:08:07.038888Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011115631455557681, max=1.0â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b359a263f74489d9bf7ecb82a0a7699"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241127_145403-l1wm20tv</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/zhukov01/huggingface/runs/l1wm20tv' target=\"_blank\">./results/tweetsum-finetuned</a></strong> to <a href='https://wandb.ai/zhukov01/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/zhukov01/huggingface' target=\"_blank\">https://wandb.ai/zhukov01/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/zhukov01/huggingface/runs/l1wm20tv' target=\"_blank\">https://wandb.ai/zhukov01/huggingface/runs/l1wm20tv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1100' max='1100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1100/1100 13:57, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>1.281900</td>\n      <td>0.652078</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.528200</td>\n      <td>0.627011</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2618: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\nThere were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"('./finetuned_bart_tweetsum1/tokenizer_config.json',\n './finetuned_bart_tweetsum1/special_tokens_map.json',\n './finetuned_bart_tweetsum1/vocab.json',\n './finetuned_bart_tweetsum1/merges.txt',\n './finetuned_bart_tweetsum1/added_tokens.json',\n './finetuned_bart_tweetsum1/tokenizer.json')"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Build the customized DataLoader class for fine-tunning\nfrom torch.utils.data import DataLoader, Dataset\nfrom datasets import load_dataset\n\ntweetsum_train_dataloader = DataLoader(tweetsum_train_dataset, batch_size=8, shuffle=True)\ntweetsum_validation_dataloader = DataLoader(tweetsum_validation_dataset, batch_size=8)\ntweetsum_test_dataloader = DataLoader(tweetsum_test_dataset, batch_size=8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:24:07.315390Z","iopub.execute_input":"2024-11-27T15:24:07.315780Z","iopub.status.idle":"2024-11-27T15:24:07.321599Z","shell.execute_reply.started":"2024-11-27T15:24:07.315747Z","shell.execute_reply":"2024-11-27T15:24:07.320730Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:19:27.104096Z","iopub.execute_input":"2024-11-27T15:19:27.104876Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"!pip install rouge_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:21:16.653977Z","iopub.execute_input":"2024-11-27T15:21:16.654351Z","iopub.status.idle":"2024-11-27T15:21:26.881992Z","shell.execute_reply.started":"2024-11-27T15:21:16.654323Z","shell.execute_reply":"2024-11-27T15:21:26.880894Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=9d89f8dc5d81f3963937a591916bd2938acb354bf7e932c4ea5936ec416ca2d3\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Model evaluating using ROUGE\nfrom evaluate import load\nimport torch\n\n# Load ROUGE metric\nrouge = load(\"rouge\")\n\n# Function to generate predictions\ndef generate_predictions(model, tokenizer, dataset):\n    predictions = []\n    references = []\n\n    for example in dataset:\n        # Prepare the input dialogue\n        inputs = tokenizer(\n            example[\"dialogue\"], \n            return_tensors=\"pt\", \n            max_length=512, \n            truncation=True, \n            padding=\"max_length\"\n        )\n        \n        # Move inputs to GPU if available\n        inputs = {k: v.to(\"cuda\") for k, v in inputs.items()} if torch.cuda.is_available() else inputs\n        \n        # Generate summary\n        with torch.no_grad():\n            outputs = model.generate(\n                input_ids=inputs[\"input_ids\"], \n                attention_mask=inputs[\"attention_mask\"], \n                max_length=128, \n                min_length=30, \n                do_sample=False\n            )\n        \n        # Decode the generated summary\n        generated_summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n        \n        # Append generated summary and reference summary\n        predictions.append(generated_summary)\n        references.append(example[\"summary\"])\n    \n    return predictions, references\n\n# Generate predictions and references\ntest_predictions, test_references = generate_predictions(model, tokenizer, tweetsum_validation_dataloader)\n\n# Compute ROUGE scores\nrouge_results = rouge.compute(predictions=test_predictions, references=test_references)\n\n# Print ROUGE scores\nprint(\"ROUGE Scores:\")\nfor key, value in rouge_results.items():\n    print(f\"{key}: {value:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:24:12.600274Z","iopub.execute_input":"2024-11-27T15:24:12.600618Z","iopub.status.idle":"2024-11-27T15:24:29.925043Z","shell.execute_reply.started":"2024-11-27T15:24:12.600589Z","shell.execute_reply":"2024-11-27T15:24:29.924148Z"}},"outputs":[{"name":"stdout","text":"ROUGE Scores:\nrouge1: 0.4787\nrouge2: 0.2325\nrougeL: 0.4190\nrougeLsum: 0.4161\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}